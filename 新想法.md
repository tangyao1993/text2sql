# 基于多租户的小模型微调方案
## 第一步：训练一个强大的基础模型（Base Model）
- 选择一个优秀的开源代码模型作为起点，例如 CodeLlama, StarCoder2, 或 Phi-3-medium。
- 在一个通用的、公开的Text-to-SQL数据集（如Spider、BIRD等）上对这个模型进行初步微调。这一步的目的是让模型具备将自然语言转化为标准SQL的通用能力。这个训练好的模型就是您的“通用基础模型”。

## 第二步：针对不同的租户进行个性化LoRA微调
- 数据库Schema：即所有相关表的CREATE TABLE语句。
- 训练样本：一批针对他们数据库的“自然语言问题 -> 正确的SQL查询”的配对数据。通常，50-200个高质量的样本就能取得不错的效果。这些数据是训练LoRA的关键。

## 第三步：推理与服务
- 推理服务器（Inference Server）在启动时加载“通用基础模型”。
- 当收到一个来自“客户C”的API请求时，您的系统会：
- 识别请求来源是“客户C”。
- 动态加载 lora_adapter_client_c.safetensors 并将其应用（attach）到基础模型上。
- 使用这个“激活了客户C知识”的组合模型来处理请求，生成SQL。
- 请求处理完毕后，可以卸载（detach）该LoRA适配器，以服务其他客户的请求。
- 为了提高效率，像 vLLM 或 Text Generation Inference (TGI) 这样的现代推理框架已经原生支持动态加载和切换LoRA适配器，可以非常高效地处理这种多租户请求。

## 提示词工程
- 当您为某个企业微调了一个LoRA适配器后，模型已经通过训练“记住”了该企业的Schema、业务逻辑和查询风格。知识已经从提示词（Prompt）内化到了模型参数（LoRA权重）中。

- 此时，您的提示词会变得非常简洁：

    简单的任务指令: “根据问题生成SQL查询。”（甚至这个都可以简化）

    用户的实际问题: “查询上周销售额最高的产品是什么？”

    (可选) 动态上下文: 比如 current_date: '2025-09-04'。

强烈建议通过rag的方式把相关的Schema，指标、度量、专业术语的计算公式等放入提示词

## 数据集训练
1.  **提供数据源 (The Data Sources)**
    *   **“问题-SQL”数据文件**: 一个`.jsonl`文件，每一行包含`"question"`和`"query"`字段。还有一个`"db_id"`字段，用来告诉框架去哪里找对应的Schema。
        ```json
        // train_data.jsonl
        {"db_id": "sales_db", "question": "哪个产品卖得最好?", "query": "SELECT ..."}
        {"db_id": "sales_db", "question": "上周的总收入是多少?", "query": "SELECT ..."}
        ```
    *   **Schema文件**: 按照`db_id`组织好的，包含DDL语句的`.sql`文件。
        ```sql
        // schemas/sales_db.sql
        CREATE TABLE products (...);
        CREATE TABLE sales (...);
        ```

2.  **定义一个Prompt模板 (The Prompt Template)**
    您需要在一个地方（通常是配置文件或一个单独的文本文件）定义一个包含**占位符**的字符串模板。这个模板精确地描述了最终的Prompt应该长什么样。

    **一个典型的Text-to-SQL模板可能如下：**
    ```text
    ### Instruction:
    You are an expert MySQL assistant. Given the database schema and a user question, generate a valid SQL query.

    ### Database Schema:
    {{schema}}

    ### User Question:
    {{question}}

    ### SQL Answer:
    {{answer}}
    ```
    这里的 `{{schema}}`, `{{question}}`, 和 `{{answer}}` 就是占位符。

#### **训练框架的任务 (自动化拼接和训练)**

当您启动训练任务时，训练框架（例如`axolotl`, `LLaMA Factory`, 或者Hugging Face的`SFTTrainer`）会在后台执行以下循环：

1.  **读取一行数据**: 从 `train_data.jsonl` 中读取一行，例如：`{"db_id": "sales_db", "question": "哪个产品卖得最好?", "query": "SELECT ..."}`。

2.  **获取对应Schema**: 根据`"db_id": "sales_db"`，框架会自动去 `schemas/` 目录下找到并读取 `sales_db.sql` 文件的全部内容。

3.  **填充模板**: 框架会拿起您的Prompt模板，然后像做填空题一样，将读取到的数据填充进去：
    *   `{{schema}}` 被替换成 `sales_db.sql` 文件的完整内容。
    *   `{{question}}` 被替换成 `"哪个产品卖得最好?"`。
    *   `{{answer}}` 被替换成 `"SELECT ..."`。

4.  **生成最终Prompt**: 此时，一个我们之前讨论过的、完整的、可供训练的Prompt就在内存中生成了。

5.  **训练模型**: 框架将这个最终生成的Prompt喂给模型，进行一步训练（计算损失、反向传播、更新LoRA权重）。

6.  **重复**: 框架接着处理`train_data.jsonl`的下一行，重复上述1-5步，直到所有数据都被处理完毕。


## 数据集构建
1. 人工标注和审核
2. 提供完整的DDL 让大模型生成，但是需人工审核或者自动化脚本验证

