# 详细技术方案

好的，我们来深入探讨一下方案二（数据模型作为RAG信息，通过LLM生成SQL）的详细技术方案。

这是一个业界领先且经过验证的架构，可以构建一个强大、灵活且可扩展的Text-to-SQL系统。整个系统可以分为**离线处理**和**在线处理**两个阶段。

---

### **总体架构图**

```
+---------------------------------------------------------------------------------+
|                                  用户 (User)                                  |
|                                      |                                        |
|                               "上周客单价最高的门店是哪个？"                      |
|                                      |                                        |
+--------------------------------------|----------------------------------------+
|                                      ▼                                        |
|                           在线处理 (Online Inference)                           |
|                                                                                 |
|  +-----------------------+      +------------------------+      +-------------+  |
|  |     Query 解析模块     |----->|     RAG 检索模块      |----->| Prompt 构建模块|  |
|  | (意图识别/实体提取)      |      | (Schema & Doc Retriever) |      | (Prompt Engine)|  |
|  +-----------------------+      +------------------------+      +-------------+  |
|                                           ▲                       |             |
|                                           |                       |             |
|  +----------------------------------------+-----------------------+             |
|  |                    离线处理 (Offline Processing)                   |             |
|  |                                                                 |             |
|  |  +-----------------------+      +--------------------------+    |             |
|  |  |   元数据同步 (Metadata Sync)|----->|     知识库构建 (Indexing)    |    |             |
|  |  | (Tables, Columns, Keys) |      | (Vectorize & Store in DB)|    |             |
|  |  +-----------------------+      +--------------------------+    |             |
|  +-----------------------------------------------------------------+             |
|                                                                                 |
|                                                                                 ▼
|                                                                   +-----------------------+
|                                                                   |      LLM 推理模块     |
|                                                                   | (SQL Generation)      |
|                                                                   +-----------------------+
|                                                                                 |
|                                                                                 ▼
|                                                                   +-----------------------+
|                                                                   |    SQL 后处理 & 验证   |
|                                                                   | (Validation & Fix)    |
|                                                                   +-----------------------+
|                                                                                 |
|           .--------------------------------------------------------------------'
|           | (执行成功)
|           ▼
|  +------------------+      +----------------------+
|  |   数据库执行      |----->|     结果可视化/呈现    |
|  | (DB Execution)   |      | (Data Visualization) |
|  +------------------+      +----------------------+
|
|
'----------- (执行失败) ------------> 让 LLM 自我修正 (Self-Correction)
```

---

### **技术选型**

* **后端语言**: python3.10

*   **LLM**: ollama  deepseek-r1:32b
*   **Embedding模型**: BGE-large-zh
*   **向量数据库**: ChromaDB 
*   **开发框架**: LangChain, langgraph
*   **SQL验证/解析**: `sqlglot` (Python库，功能强大)

### **第一阶段：离线处理 (Offline Processing)**

离线处理的目标是构建一个高质量、可供LLM理解和检索的知识库。这一步至关重要，直接决定了在线阶段的召回准确率和最终SQL的质量。

#### **1. 元数据同步 (Metadata Sync)**

配置目前数据源，通过一个按钮点击，然后读取数据库元数据，把这部分数据存储到数据库，然后通过一个菜单可以去编辑，编辑表的字段可通过文档内容示例中获取，部分数据可使用LLM填充外加人工修改和检查，最终形成单表的Chunk

你需要一个自动化的脚本或服务，定期从你的业务数据库中抽取所有相关的元数据。

*   **表信息 (Tables)**: 表名 (`sales_orders`)、表的注释（`-- 订单事实表，记录每一笔交易`）。表的注释非常重要，能帮助LLM理解表的业务含义。
*   **字段信息 (Columns)**: 字段名 (`customer_id`)、数据类型 (`BIGINT`)、字段注释 (`-- 购买用户的ID`)。字段注释同样关键。
*   **关系信息 (Relationships)**: 主键、外键信息。这直接告诉了LLM表与表之间应该如何`JOIN`。
*   **(可选) 业务规则和指标定义**:
    *   **复杂指标**: 例如，“客单价”的定义是 `sum(payment_amount) / count(distinct order_id)`。将这些业务术语和其对应的SQL表达式存储起来。
    *   **枚举值**: 字段中一些代码的含义，例如 `status=1` 代表“支付成功”，`status=2` 代表“支付失败”。

#### **2. 知识库构建与向量化 (Knowledge Base Construction & Indexing)**

将同步来的元数据结构化处理，并进行向量化，存入向量数据库（如ChromaDB, Pinecone, FAISS等）以备检索。

*   **分块策略 (Chunking Strategy)**: 不要把整个数据库的schema作为一个巨大的文档。合理的做法是**以“表”为单位**，或者以“业务域”（如销售域、用户域）为单位进行切分。每个文档（Chunk）应包含：
    *   表的`CREATE TABLE`语句，因为它包含了最丰富的结构信息。
    *   表和所有字段的中文注释。
    *   该表相关的业务指标定义（如果存在）。

* **文档内容示例 (Chunk for Vectorization)**:

  ````text
  **示例：`orders` 表的Chunk文档**
  
  ```markdown
  # Table: orders
  ## Description
  订单事实表，记录了每一笔成功的用户交易。与用户表(users)和产品表(products)关联。
  
  ## Schema
  ```sql
  CREATE TABLE orders (
      order_id VARCHAR(50) PRIMARY KEY COMMENT '订单唯一ID',
      user_id BIGINT COMMENT '下单用户ID',
      product_id BIGINT COMMENT '购买的产品ID',
      payment_amount DECIMAL(10, 2) COMMENT '用户实际支付金额',
      order_status INT COMMENT '订单状态',
      created_at DATETIME COMMENT '订单创建时间'
      FOREIGN KEY (user_id) REFERENCES users(user_id)
  );
  ```
  
  ## Business Info
  ### Business Terms
  - **销售额 (GMV)**: SUM(payment_amount)
  - **订单量**: COUNT(DISTINCT order_id)
  - **客单价**: SUM(payment_amount) / COUNT(DISTINCT user_id)
  
  ### Enum Values
  - **order_status**: `1` means '支付成功', `2` means '待支付', `3` means '已取消'.
  
  ### Synonyms
  - **Table Synonyms**: 销售订单, 交易记录
  - **Column Synonyms**: payment_amount -> 支付金额, 销售额, 收入; created_at -> 下单时间, 购买日期
  ```
  ````

*   **向量化 (Embedding)**: 使用一个高质量的Embedding模型将上述处理好的文本块转换为向量，并存入向量数据库。

---

### **第二阶段：在线处理 (Online Inference)**

这是用户提问后，实时生成SQL的流程。

#### **1. Query 解析 (Query Parsing) - 可选但推荐**

在将用户问题直接用于RAG之前，可以先做一个简单的预处理，这能提升召回的准确性。

*   **实体提取**: 识别问题中的指标、维度、时间等。例如，从“上周客单价最高的门店是哪个？”中提取出“客单价”、“门店”、“上周”。
*   **意图识别**: 判断查询类型，是简单查询还是复杂分析。

这个模块的输出可以用来**优化RAG的检索查询**。例如，将用户问题和提取出的实体一起作为检索的输入。

#### **2. RAG 检索模块 (Schema & Doc Retriever)**

这是系统的核心之一。根据用户的查询，从构建好的知识库中检索最相关的“上下文”。

*   **检索策略**:
    1.  **向量检索**: 将用户问题（或“问题+实体”）进行向量化，去向量数据库中进行相似度查询，召回Top-K（例如K=3）个最相关的表信息文档。
    2.  **关键词/BM25检索**: 作为补充，可以使用关键词检索来确保一些专有名词（如表名、字段名）能被精确匹配到。
    3.  **混合检索**: 将向量检索和关键词检索的结果进行融合排序（如Reciprocal Rank Fusion），得到最终的召-回列表。

*   **检索结果**: 检索出的内容就是与用户问题最相关的几张表的详细信息（`CREATE TABLE`语句、注释等）。

#### **3. Prompt 构建模块 (Prompt Engine)**

这是另一个核心，高质量的Prompt是生成准确SQL的保证。Prompt应遵循一个精心设计的模板，至少包含以下部分：

*   **角色和任务指令 (Role & Instruction)**:
    > "你是一个世界级的数据库专家和SQL工程师。你的任务是根据用户的问题和提供的数据表结构，生成一段准确、高效的SQL查询。请严格遵循以下规则：\n1. 只使用提供的表和字段。\n2. 注意表之间的关联关系。\n3. 如果问题的计算逻辑复杂，请使用CTE（WITH语句）来保证SQL的可读性。\n4. 不要编造任何不存在的字段。"

*   **数据模型上下文 (Schema Context)**:
    > "请根据以下数据表结构生成SQL：\n\n-- 表1\n[这里插入RAG检索到的第一个表的CREATE TABLE语句和注释]\n\n-- 表2\n[这里插入RAG检索到的第二个表的CREATE TABLE语句和注释]\n..."

*   **(可选) 业务规则/指标上下文 (Business Context)**:
    > "请注意以下业务定义：\n- 客单价 = SUM(支付金额) / COUNT(DISTINCT 订单ID)"

*   **(可选) 少样本示例 (Few-shot Examples)**:
    > "这里有一些示例：\n问题: '查询北京地区的总销售额'\nSQL: `SELECT SUM(payment_amount) FROM sales_orders WHERE region = '北京';`"

*   **用户问题 (User Question)**:
    > "现在，请根据以上信息，为以下问题生成SQL：\n'上周客单价最高的门店是哪个？'"

*   **输出格式指令 (Output Format)**:
    > "请将SQL代码包裹在\`\`\`sql ... \`\`\`中。"

#### **4. LLM 推理模块 (SQL Generation)**

将构建好的Prompt发送给一个强大的LLM（如GPT-4, Claude 3, Llama 3，或微调过的Code Llama等）。模型会根据上下文生成SQL。

#### **5. SQL 后处理与验证 (Validation & Self-Correction)**

这是确保系统可靠性的关键闭环。

*   **语法检查**: 使用一个SQL解析库（如 `sqlglot` 或 `jsqlparse`）对LLM生成的SQL进行语法检查。如果语法错误，可以直接返回错误信息或进入修正流程。
*   **执行验证**:
    1.  **尝试执行**: 连接到一个**只读权限**的数据库副本，或者使用一个SQL执行引擎（如DuckDB）来尝试运行生成的SQL。
    2.  **Dry Run**: 很多数据库支持“Dry Run”模式，可以检查查询的有效性而不真正消耗计算资源。
    3.  **捕获异常**: 如果执行报错（例如，字段不存在、类型不匹配），捕获数据库返回的错误信息。

*   **自我修正循环 (Self-Correction Loop)**:
    *   如果验证失败，将原始问题、第一次生成的错误SQL以及数据库的报错信息，一起重新组合成一个新的Prompt，要求LLM进行修正。
    *   **修正Prompt示例**:
        > "你上次生成的SQL执行时出错了。请根据下面的错误信息修正你的SQL。\n原始问题: [...]\n错误的SQL: [...]\n数据库报错: `ERROR: column "store_name" does not exist`\n请重新生成正确的SQL。"
    *   这个修正过程可以循环1-2次。

### **第三阶段：结果呈现**

*   **数据库执行 (DB Execution)**: 验证通过后，在生产数据库（或其只读副本）上正式执行SQL。
*   **结果处理与可视化 (Data Visualization)**:
    *   将查询结果以表格形式返回。
    *   根据问题意图，自动选择合适的图表进行可视化（例如，时间序列问题用折线图，分布问题用柱状图）。这部分也可以再次借助LLM来建议图表类型。